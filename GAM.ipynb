{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openbox'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenbox\u001b[39;00m \u001b[39mimport\u001b[39;00m run_test\n\u001b[0;32m      3\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m      4\u001b[0m     run_test()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openbox'"
     ]
    }
   ],
   "source": [
    "from openbox import run_test\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openbox'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenbox\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openbox'"
     ]
    }
   ],
   "source": [
    "import openbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pygam import LinearGAM, s, f\n",
    "from pygam.datasets import wage\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "X, y = wage(return_X_y=True)\n",
    "\n",
    "## model\n",
    "gam = LinearGAM(s(0) + s(1) + f(2))\n",
    "gam.gridsearch(X, y)\n",
    "\n",
    "\n",
    "## plotting\n",
    "plt.figure();\n",
    "fig, axs = plt.subplots(1,3);\n",
    "\n",
    "titles = ['year', 'age', 'education']\n",
    "for i, ax in enumerate(axs):\n",
    "    XX = gam.generate_X_grid(term=i)\n",
    "    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX))\n",
    "    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX, width=.95)[1], c='r', ls='--')\n",
    "    if i == 0:\n",
    "        ax.set_ylim(-30,30)\n",
    "    ax.set_title(titles[i]);  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.read_excel('data.xlsx')\n",
    "X = df.iloc[:, 0:19].values\n",
    "y = df.iloc[:, 19].values.reshape(-1,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'g' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m gam \u001b[39m=\u001b[39m LinearGAM(lam \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m)\u001b[39m.\u001b[39mfit(X_train,y_train)\n\u001b[1;32m----> 4\u001b[0m g\n",
      "\u001b[1;31mNameError\u001b[0m: name 'g' is not defined"
     ]
    }
   ],
   "source": [
    "gam = LinearGAM(lam = 0.2).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt ,loadtxt\n",
    "X_test = loadtxt('X_test.csv', delimiter=',')\n",
    "X_train = loadtxt('X_train.csv', delimiter=',')\n",
    "y_test = loadtxt('y_test.csv', delimiter=',')\n",
    "y_train = loadtxt('y_train.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lams = [lam] * 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'l'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [53], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator_checks\u001b[39;00m \u001b[39mimport\u001b[39;00m check_estimator\n\u001b[1;32m----> 3\u001b[0m check_estimator(RegularizedRegressor())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\estimator_checks.py:624\u001b[0m, in \u001b[0;36mcheck_estimator\u001b[1;34m(estimator, generate_only, Estimator)\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[39mfor\u001b[39;00m estimator, check \u001b[39min\u001b[39;00m checks_generator():\n\u001b[0;32m    623\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 624\u001b[0m         check(estimator)\n\u001b[0;32m    625\u001b[0m     \u001b[39mexcept\u001b[39;00m SkipTest \u001b[39mas\u001b[39;00m exception:\n\u001b[0;32m    626\u001b[0m         \u001b[39m# SkipTest is thrown when pandas can't be imported, or by checks\u001b[39;00m\n\u001b[0;32m    627\u001b[0m         \u001b[39m# that are in the xfail_checks tag\u001b[39;00m\n\u001b[0;32m    628\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39mstr\u001b[39m(exception), SkipTestWarning)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_testing.py:320\u001b[0m, in \u001b[0;36m_IgnoreWarnings.__call__.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[0;32m    319\u001b[0m     warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategory)\n\u001b[1;32m--> 320\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\estimator_checks.py:1726\u001b[0m, in \u001b[0;36mcheck_estimators_dtypes\u001b[1;34m(name, estimator_orig)\u001b[0m\n\u001b[0;32m   1724\u001b[0m estimator \u001b[39m=\u001b[39m clone(estimator_orig)\n\u001b[0;32m   1725\u001b[0m set_random_state(estimator, \u001b[39m1\u001b[39m)\n\u001b[1;32m-> 1726\u001b[0m estimator\u001b[39m.\u001b[39;49mfit(X_train, y)\n\u001b[0;32m   1728\u001b[0m \u001b[39mfor\u001b[39;00m method \u001b[39min\u001b[39;00m methods:\n\u001b[0;32m   1729\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, method):\n",
      "Cell \u001b[1;32mIn [50], line 23\u001b[0m, in \u001b[0;36mRegularizedRegressor.fit\u001b[1;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 23\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml \u001b[39m=\u001b[39m kwargs[\u001b[39m'\u001b[39;49m\u001b[39ml\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     24\u001b[0m     X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmatrix(X)\n\u001b[0;32m     25\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmatrix(y)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'l'"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "\n",
    "check_estimator(RegularizedRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'l'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Daniel\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"C:\\Users\\Daniel\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Daniel\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Daniel\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Daniel\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Daniel\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Daniel\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_12112\\580732582.py\", line 23, in fit\nKeyError: 'l'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [50], line 58\u001b[0m\n\u001b[0;32m     50\u001b[0m scoring_func \u001b[39m=\u001b[39m make_scorer(mean_squared_error)\n\u001b[0;32m     51\u001b[0m bayes_search \u001b[39m=\u001b[39m BayesSearchCV(estimator \u001b[39m=\u001b[39m RegularizedRegressor(), \n\u001b[0;32m     52\u001b[0m                            search_spaces\u001b[39m=\u001b[39m {\n\u001b[0;32m     53\u001b[0m                                 \u001b[39m'\u001b[39m\u001b[39ml\u001b[39m\u001b[39m'\u001b[39m:Real(\u001b[39m1e-6\u001b[39m, \u001b[39m1\u001b[39m, prior\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlog-uniform\u001b[39m\u001b[39m'\u001b[39m),                                \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m                            cv \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m,\n\u001b[0;32m     57\u001b[0m                            n_jobs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m);\n\u001b[1;32m---> 58\u001b[0m bayes_search \u001b[39m=\u001b[39m bayes_search\u001b[39m.\u001b[39;49mfit(X, y);\n\u001b[0;32m     59\u001b[0m \u001b[39m# bayes_search.score(X_test,y_test), bayes_search.cv_results_['mean_test_score'].mean()\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[39m# print(cross_val_score(RegularizedRegressor(),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39m#                       fit_params={'l':0.1},\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[39m#                       scoring = 'neg_mean_squared_error'))\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\searchcv.py:466\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[1;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_kwargs_ \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_kwargs)\n\u001b[1;32m--> 466\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, groups\u001b[39m=\u001b[39;49mgroups, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    468\u001b[0m \u001b[39m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_train_score:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\searchcv.py:512\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[39mwhile\u001b[39;00m n_iter \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    509\u001b[0m     \u001b[39m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     n_points_adjusted \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(n_iter, n_points)\n\u001b[1;32m--> 512\u001b[0m     optim_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step(\n\u001b[0;32m    513\u001b[0m         search_space, optimizer,\n\u001b[0;32m    514\u001b[0m         evaluate_candidates, n_points\u001b[39m=\u001b[39;49mn_points_adjusted\n\u001b[0;32m    515\u001b[0m     )\n\u001b[0;32m    516\u001b[0m     n_iter \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m n_points\n\u001b[0;32m    518\u001b[0m     \u001b[39mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\searchcv.py:408\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[1;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[39m# make lists into dictionaries\u001b[39;00m\n\u001b[0;32m    406\u001b[0m params_dict \u001b[39m=\u001b[39m [point_asdict(search_space, p) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m params]\n\u001b[1;32m--> 408\u001b[0m all_results \u001b[39m=\u001b[39m evaluate_candidates(params_dict)\n\u001b[0;32m    409\u001b[0m \u001b[39m# Feed the point and objective value back into optimizer\u001b[39;00m\n\u001b[0;32m    410\u001b[0m \u001b[39m# Optimizer minimizes objective, hence provide negative score\u001b[39;00m\n\u001b[0;32m    411\u001b[0m local_results \u001b[39m=\u001b[39m all_results[\u001b[39m\"\u001b[39m\u001b[39mmean_test_score\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(params):]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m         clone(base_estimator),\n\u001b[0;32m    825\u001b[0m         X,\n\u001b[0;32m    826\u001b[0m         y,\n\u001b[0;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    833\u001b[0m     )\n\u001b[0;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    836\u001b[0m     )\n\u001b[0;32m    837\u001b[0m )\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'l'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import fbeta_score, make_scorer, mean_squared_error\n",
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class RegularizedRegressor(BaseEstimator):\n",
    "    def __init__(self, l = 0.01):\n",
    "        self.l = l\n",
    "\n",
    "    def combine(self, inputs):\n",
    "        return sum([i*w for (i,w) in zip([1] + inputs, self.weights)])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self.combine(x) for x in X]\n",
    "\n",
    "    def classify(self, inputs):\n",
    "        return sign(self.predict(inputs))\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        self.l = kwargs['l']\n",
    "        X = np.matrix(X)\n",
    "        y = np.matrix(y)\n",
    "        W = (X.transpose() * X).getI() * X.transpose() * y\n",
    "\n",
    "        self.weights = [w[0] for w in W.tolist()]\n",
    "\n",
    "    def get_params(self, deep = False):\n",
    "        return {'l':self.l}\n",
    "\n",
    "    # def set_params(self, **parameters):\n",
    "    #     for parameter, value in parameters.items():\n",
    "    #         setattr(self, parameter, value)\n",
    "    #     return self\n",
    "\n",
    "\n",
    "\n",
    "X = np.matrix([[0, 0], [1, 0], [0, 1], [1, 1],[0,1]])\n",
    "y = np.matrix([0, 1, 1, 0,1]).transpose()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "scoring_func = make_scorer(mean_squared_error)\n",
    "bayes_search = BayesSearchCV(estimator = RegularizedRegressor(), \n",
    "                           search_spaces= {\n",
    "                                'l':Real(1e-6, 1, prior='log-uniform'),                                \n",
    "                           },\n",
    "                           scoring = scoring_func,\n",
    "                           cv = 2,\n",
    "                           n_jobs = -1);\n",
    "bayes_search = bayes_search.fit(X, y);\n",
    "# bayes_search.score(X_test,y_test), bayes_search.cv_results_['mean_test_score'].mean()\n",
    "\n",
    "# print(cross_val_score(RegularizedRegressor(),\n",
    "#                       X,\n",
    "#                       y, \n",
    "#                       fit_params={'l':0.1},\n",
    "#                       scoring = 'neg_mean_squared_error'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# RegularizedRegressor().get_params()[\"l\"]\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# RegularizedRegressor().get_params()[\"l\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=4.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:862\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m     tasks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ready_batches\u001b[39m.\u001b[39;49mget(block\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    863\u001b[0m \u001b[39mexcept\u001b[39;00m queue\u001b[39m.\u001b[39mEmpty:\n\u001b[0;32m    864\u001b[0m     \u001b[39m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[0;32m    865\u001b[0m     \u001b[39m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[39m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[0;32m    869\u001b[0m     \u001b[39m# workers.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[1;32m--> 168\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmatrix([[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m], [\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m], [\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m], [\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m]])\n\u001b[0;32m     33\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmatrix([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mtranspose()\n\u001b[1;32m---> 35\u001b[0m \u001b[39mprint\u001b[39m(cross_val_score(RegularizedRegressor(),\n\u001b[0;32m     36\u001b[0m                       X,\n\u001b[0;32m     37\u001b[0m                       y, \n\u001b[0;32m     38\u001b[0m                       fit_params\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39ml\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m0.1\u001b[39;49m},\n\u001b[0;32m     39\u001b[0m                       scoring \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mneg_mean_squared_error\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:873\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    870\u001b[0m n_jobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_effective_n_jobs\n\u001b[0;32m    871\u001b[0m big_batch_size \u001b[39m=\u001b[39m batch_size \u001b[39m*\u001b[39m n_jobs\n\u001b[1;32m--> 873\u001b[0m islice \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(iterator, big_batch_size))\n\u001b[0;32m    874\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(islice) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    875\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:333\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    331\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(X)\n\u001b[0;32m    332\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits \u001b[39m>\u001b[39m n_samples:\n\u001b[1;32m--> 333\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    334\u001b[0m         (\n\u001b[0;32m    335\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot have number of splits n_splits=\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m greater\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    336\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m than the number of samples: n_samples=\u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    337\u001b[0m         )\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits, n_samples)\n\u001b[0;32m    338\u001b[0m     )\n\u001b[0;32m    340\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msplit(X, y, groups):\n\u001b[0;32m    341\u001b[0m     \u001b[39myield\u001b[39;00m train, test\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=4."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import fbeta_score, make_scorer, mean_squared_error\n",
    "\n",
    "scoring_func = make_scorer(mean_squared_error)\n",
    "\n",
    "class GAM_estimator:\n",
    "    def __init__(self, lm1 = 0.01):\n",
    "        self.l = l\n",
    "\n",
    "    def combine(self, inputs):\n",
    "        return sum([i*w for (i,w) in zip([1] + inputs, self.weights)])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self.combine(x) for x in X]\n",
    "\n",
    "    def classify(self, inputs):\n",
    "        return sign(self.predict(inputs))\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        self.l = kwargs['l']\n",
    "        X = np.matrix(X)\n",
    "        y = np.matrix(y)\n",
    "        W = (X.transpose() * X).getI() * X.transpose() * y\n",
    "\n",
    "        self.weights = [w[0] for w in W.tolist()]\n",
    "        gam = LinearGAM(lam = 0.2).fit(X_train,y_train)\n",
    "\n",
    "    def get_params(self, deep = False):\n",
    "        return {'l':self.l}\n",
    "\n",
    "    \n",
    "\n",
    "X = np.matrix([[0, 0], [1, 0], [0, 1], [1, 1]])\n",
    "y = np.matrix([0, 1, 1, 0]).transpose()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 524288) |                     | Elapsed Time: 0:00:00 ETA:  --:--:--\n",
      "  0% (1 of 524288) |              | Elapsed Time: 0:00:01 ETA:  8 days, 9:25:42\n",
      "  0% (2 of 524288) |             | Elapsed Time: 0:00:02 ETA:  7 days, 16:48:57\n",
      "  0% (3 of 524288) |             | Elapsed Time: 0:00:03 ETA:  7 days, 11:14:13\n",
      "  0% (4 of 524288) |             | Elapsed Time: 0:00:05 ETA:  7 days, 21:00:56\n",
      "  0% (5 of 524288) |             | Elapsed Time: 0:00:06 ETA:  7 days, 12:37:53\n",
      "  0% (6 of 524288) |              | Elapsed Time: 0:00:07 ETA:  7 days, 4:21:45\n",
      "  0% (7 of 524288) |              | Elapsed Time: 0:00:08 ETA:  7 days, 1:16:30\n",
      "  0% (8 of 524288) |              | Elapsed Time: 0:00:09 ETA:  7 days, 0:03:46\n",
      "  0% (9 of 524288) |              | Elapsed Time: 0:00:10 ETA:  7 days, 0:40:16\n",
      "  0% (10 of 524288) |             | Elapsed Time: 0:00:12 ETA:  7 days, 0:03:22\n",
      "  0% (11 of 524288) |            | Elapsed Time: 0:00:13 ETA:  6 days, 21:56:50\n",
      "  0% (12 of 524288) |            | Elapsed Time: 0:00:14 ETA:  6 days, 17:26:15\n",
      "  0% (13 of 524288) |             | Elapsed Time: 0:00:15 ETA:  8 days, 7:27:31\n",
      "  0% (14 of 524288) |            | Elapsed Time: 0:00:17 ETA:  8 days, 21:21:21\n",
      "  0% (15 of 524288) |             | Elapsed Time: 0:00:18 ETA:  7 days, 3:47:12\n",
      "  0% (16 of 524288) |             | Elapsed Time: 0:00:19 ETA:  7 days, 4:09:02\n",
      "  0% (17 of 524288) |            | Elapsed Time: 0:00:20 ETA:  7 days, 20:34:07\n",
      "  0% (18 of 524288) |            | Elapsed Time: 0:00:22 ETA:  7 days, 18:02:00\n",
      "  0% (19 of 524288) |             | Elapsed Time: 0:00:23 ETA:  7 days, 3:04:33\n",
      "  0% (20 of 524288) |             | Elapsed Time: 0:00:24 ETA:  7 days, 0:19:46\n",
      "  0% (21 of 524288) |             | Elapsed Time: 0:00:25 ETA:  7 days, 8:34:54\n",
      "  0% (22 of 524288) |            | Elapsed Time: 0:00:26 ETA:  6 days, 22:40:54\n",
      "  0% (23 of 524288) |            | Elapsed Time: 0:00:27 ETA:  6 days, 14:53:10\n",
      "  0% (24 of 524288) |            | Elapsed Time: 0:00:28 ETA:  6 days, 14:40:09\n",
      "  0% (25 of 524288) |            | Elapsed Time: 0:00:30 ETA:  6 days, 22:19:44\n",
      "  0% (26 of 524288) |             | Elapsed Time: 0:00:31 ETA:  7 days, 6:51:10\n",
      "  0% (27 of 524288) |            | Elapsed Time: 0:00:32 ETA:  6 days, 20:14:44\n",
      "  0% (28 of 524288) |            | Elapsed Time: 0:00:33 ETA:  6 days, 11:04:37\n",
      "  0% (29 of 524288) |             | Elapsed Time: 0:00:34 ETA:  6 days, 9:46:58\n",
      "  0% (30 of 524288) |            | Elapsed Time: 0:00:35 ETA:  6 days, 10:30:09\n",
      "  0% (31 of 524288) |            | Elapsed Time: 0:00:36 ETA:  6 days, 12:34:02\n",
      "  0% (32 of 524288) |            | Elapsed Time: 0:00:37 ETA:  6 days, 10:37:54\n",
      "  0% (33 of 524288) |             | Elapsed Time: 0:00:38 ETA:  6 days, 8:22:01\n",
      "  0% (34 of 524288) |            | Elapsed Time: 0:00:39 ETA:  6 days, 18:39:54\n",
      "  0% (35 of 524288) |            | Elapsed Time: 0:00:41 ETA:  6 days, 21:55:33\n",
      "  0% (36 of 524288) |             | Elapsed Time: 0:00:42 ETA:  7 days, 2:13:41\n",
      "  0% (37 of 524288) |             | Elapsed Time: 0:00:43 ETA:  7 days, 5:40:09\n",
      "  0% (38 of 524288) |            | Elapsed Time: 0:00:44 ETA:  6 days, 17:57:22\n",
      "  0% (39 of 524288) |            | Elapsed Time: 0:00:45 ETA:  6 days, 13:45:31\n",
      "  0% (40 of 524288) |            | Elapsed Time: 0:00:46 ETA:  6 days, 13:56:38\n",
      "  0% (41 of 524288) |            | Elapsed Time: 0:00:47 ETA:  6 days, 16:21:47\n",
      "  0% (42 of 524288) |            | Elapsed Time: 0:00:48 ETA:  6 days, 15:34:51\n",
      "  0% (43 of 524288) |            | Elapsed Time: 0:00:49 ETA:  6 days, 13:33:31\n",
      "  0% (44 of 524288) |            | Elapsed Time: 0:00:51 ETA:  6 days, 11:44:16\n",
      "  0% (45 of 524288) |            | Elapsed Time: 0:00:52 ETA:  6 days, 11:34:25\n",
      "  0% (46 of 524288) |            | Elapsed Time: 0:00:53 ETA:  6 days, 14:04:43\n",
      "  0% (47 of 524288) |            | Elapsed Time: 0:00:54 ETA:  6 days, 15:10:19\n",
      "  0% (48 of 524288) |            | Elapsed Time: 0:00:55 ETA:  6 days, 14:31:11\n",
      "  0% (49 of 524288) |            | Elapsed Time: 0:00:56 ETA:  6 days, 13:58:49\n",
      "  0% (50 of 524288) |            | Elapsed Time: 0:00:57 ETA:  6 days, 14:11:34\n",
      "  0% (51 of 524288) |            | Elapsed Time: 0:00:58 ETA:  6 days, 11:05:26\n",
      "  0% (52 of 524288) |            | Elapsed Time: 0:00:59 ETA:  6 days, 13:40:37\n",
      "  0% (53 of 524288) |            | Elapsed Time: 0:01:00 ETA:  6 days, 18:10:52\n",
      "  0% (54 of 524288) |            | Elapsed Time: 0:01:01 ETA:  6 days, 17:51:59\n",
      "  0% (55 of 524288) |            | Elapsed Time: 0:01:03 ETA:  6 days, 18:42:46\n",
      "  0% (56 of 524288) |            | Elapsed Time: 0:01:04 ETA:  6 days, 16:49:41\n",
      "  0% (57 of 524288) |            | Elapsed Time: 0:01:05 ETA:  6 days, 15:18:41\n",
      "  0% (58 of 524288) |            | Elapsed Time: 0:01:06 ETA:  6 days, 15:34:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m lams\n\u001b[1;32m----> 2\u001b[0m gam\u001b[39m.\u001b[39;49mgridsearch(X,y, lam\u001b[39m=\u001b[39;49mlams)\n\u001b[0;32m      3\u001b[0m gam\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pygam\\pygam.py:1894\u001b[0m, in \u001b[0;36mGAM.gridsearch\u001b[1;34m(self, X, y, weights, return_scores, keep_best, objective, progress, **param_grids)\u001b[0m\n\u001b[0;32m   1892\u001b[0m         coef \u001b[39m=\u001b[39m models[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mcoef_\n\u001b[0;32m   1893\u001b[0m         gam\u001b[39m.\u001b[39mset_params(coef_\u001b[39m=\u001b[39mcoef, force\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1894\u001b[0m     gam\u001b[39m.\u001b[39;49mfit(X, y, weights)\n\u001b[0;32m   1896\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[0;32m   1897\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(error) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mon model with params:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(param_grid)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pygam\\pygam.py:920\u001b[0m, in \u001b[0;36mGAM.fit\u001b[1;34m(self, X, y, weights)\u001b[0m\n\u001b[0;32m    917\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatistics_[\u001b[39m'\u001b[39m\u001b[39mm_features\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    919\u001b[0m \u001b[39m# optimize\u001b[39;00m\n\u001b[1;32m--> 920\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pirls(X, y, weights)\n\u001b[0;32m    921\u001b[0m \u001b[39m# if self._opt == 0:\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[39m#     self._pirls(X, y, weights)\u001b[39;00m\n\u001b[0;32m    923\u001b[0m \u001b[39m# if self._opt == 1:\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[39m#     self._pirls_naive(X, y)\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pygam\\pygam.py:756\u001b[0m, in \u001b[0;36mGAM._pirls\u001b[1;34m(self, X, Y, weights)\u001b[0m\n\u001b[0;32m    753\u001b[0m U1 \u001b[39m=\u001b[39m U[:min_n_m,:min_n_m] \u001b[39m# keep only top corner of U\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[39m# update coefficients\u001b[39;00m\n\u001b[1;32m--> 756\u001b[0m B \u001b[39m=\u001b[39m Vt\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mdot(Dinv)\u001b[39m.\u001b[39mdot(U1\u001b[39m.\u001b[39mT)\u001b[39m.\u001b[39mdot(Q\u001b[39m.\u001b[39mT)\n\u001b[0;32m    757\u001b[0m coef_new \u001b[39m=\u001b[39m B\u001b[39m.\u001b[39mdot(pseudo_data)\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m    758\u001b[0m diff \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_ \u001b[39m-\u001b[39m coef_new)\u001b[39m/\u001b[39mnp\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(coef_new)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lams\n",
    "gam.gridsearch(X,y, lam=lams)\n",
    "gam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (11 of 11) |########################| Elapsed Time: 0:00:12 Time:  0:00:12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearGAM(callbacks=[Deviance(), Diffs()], fit_intercept=True, \n",
       "   max_iter=100, scale=None, \n",
       "   terms=s(0) + s(1) + s(2) + s(3) + s(4) + s(5) + s(6) + s(7) + s(8) + s(9) + s(10) + s(11) + s(12) + s(13) + s(14) + s(15) + s(16) + s(17) + s(18) + intercept,\n",
       "   tol=0.0001, verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gam.gridsearch(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearGAM                                                                                                 \n",
      "=============================================== ==========================================================\n",
      "Distribution:                        NormalDist Effective DoF:                                     49.3824\n",
      "Link Function:                     IdentityLink Log Likelihood:                                -27103.1026\n",
      "Number of Samples:                         3265 AIC:                                            54306.9699\n",
      "                                                AICc:                                            54308.581\n",
      "                                                GCV:                                             1651.4721\n",
      "                                                Scale:                                           1606.5728\n",
      "                                                Pseudo R-Squared:                                   0.6814\n",
      "==========================================================================================================\n",
      "Feature Function                  Lambda               Rank         EDoF         P > x        Sig. Code   \n",
      "================================= ==================== ============ ============ ============ ============\n",
      "s(0)                              [251.1886]           20           7.3          4.46e-01                 \n",
      "s(1)                              [251.1886]           20           4.8          4.37e-02     *           \n",
      "s(2)                              [251.1886]           20           1.9          2.87e-01                 \n",
      "s(3)                              [251.1886]           20           2.2          5.92e-02     .           \n",
      "s(4)                              [251.1886]           20           4.5          3.30e-03     **          \n",
      "s(5)                              [251.1886]           20           1.6          2.60e-02     *           \n",
      "s(6)                              [251.1886]           20           1.7          3.42e-01                 \n",
      "s(7)                              [251.1886]           20           1.7          5.17e-01                 \n",
      "s(8)                              [251.1886]           20           0.2          3.30e-03     **          \n",
      "s(9)                              [251.1886]           20           0.2          2.60e-02     *           \n",
      "s(10)                             [251.1886]           20           0.2          3.42e-01                 \n",
      "s(11)                             [251.1886]           20           0.2          5.17e-01                 \n",
      "s(12)                             [251.1886]           20           5.1          6.98e-03     **          \n",
      "s(13)                             [251.1886]           20           3.1          1.21e-02     *           \n",
      "s(14)                             [251.1886]           20           1.4          4.13e-02     *           \n",
      "s(15)                             [251.1886]           20           1.2          4.01e-01                 \n",
      "s(16)                             [251.1886]           20           4.5          5.43e-03     **          \n",
      "s(17)                             [251.1886]           20           4.1          7.40e-02     .           \n",
      "s(18)                             [251.1886]           20           3.7          1.11e-16     ***         \n",
      "intercept                                              1            0.0          1.11e-16     ***         \n",
      "==========================================================================================================\n",
      "Significance codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
      "\n",
      "WARNING: Fitting splines and a linear function to a feature introduces a model identifiability problem\n",
      "         which can cause p-values to appear significant when they are not.\n",
      "\n",
      "WARNING: p-values calculated in this manner behave correctly for un-penalized models or models with\n",
      "         known smoothing parameters, but when smoothing parameters have been estimated, the p-values\n",
      "         are typically lower than they should be, meaning that the tests reject the null too readily.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-dec6a6acdaaa>:1: UserWarning: KNOWN BUG: p-values computed in this summary are likely much smaller than they should be. \n",
      " \n",
      "Please do not make inferences based on these values! \n",
      "\n",
      "Collaborate on a solution, and stay up to date at: \n",
      "github.com/dswah/pyGAM/issues/163 \n",
      "\n",
      "  gam.summary()\n"
     ]
    }
   ],
   "source": [
    "gam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1679.0917611999314, 0.6594790809413111, 31.35208728760206)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error ,mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "mean_squared_error(y_test, gam.predict(X_test)), r2_score(y_test, gam.predict(X_test)), mean_absolute_error(y_test, gam.predict(X_test))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
