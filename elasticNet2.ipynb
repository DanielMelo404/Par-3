{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Current Version:- 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    " \n",
    " \n",
    "print(\"User Current Version:-\", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_5604\\2007514277.py:7: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from collections import Counter\n",
    "from IPython.core.display import display, HTML\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4665, 20), (4665, 19), numpy.ndarray)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, 0:19].values\n",
    "y = df.iloc[:, 19].values.reshape(-1,1)\n",
    "\n",
    "df.shape, X.shape, type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# X = X[:,cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 25)\n",
    "\n",
    "\n",
    "# Fitting regressior to the Training set\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from numpy import savetxt ,loadtxt\n",
    "\n",
    "steps = [\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('feature_slection',SelectKBest(mutual_info_regression,k=10)),\n",
    "    ('scalar2', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=4)),\n",
    "    ('scalar3', StandardScaler()),\n",
    "    ('model', ElasticNet(alpha=0.5,l1_ratio=0.6))\n",
    "]\n",
    "\n",
    "ElasticNet_pipe = Pipeline(steps)\n",
    "\n",
    "X_test = loadtxt('X_test.csv', delimiter=',')\n",
    "X_train = loadtxt('X_train.csv', delimiter=',')\n",
    "y_test = loadtxt('y_test.csv', delimiter=',')\n",
    "y_train = loadtxt('y_train.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'scalar', 'feature_slection', 'scalar2', 'poly', 'model', 'scalar__copy', 'scalar__with_mean', 'scalar__with_std', 'feature_slection__k', 'feature_slection__score_func', 'scalar2__copy', 'scalar2__with_mean', 'scalar2__with_std', 'poly__degree', 'poly__include_bias', 'poly__interaction_only', 'poly__order', 'model__alpha', 'model__copy_X', 'model__fit_intercept', 'model__l1_ratio', 'model__max_iter', 'model__normalize', 'model__positive', 'model__precompute', 'model__random_state', 'model__selection', 'model__tol', 'model__warm_start'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ElasticNet_pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.153e+06, tolerance: 1.621e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2272.4672457341258, 1926.0123846924405)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "scoring_func = make_scorer(mean_squared_error)\n",
    "bayes_search = BayesSearchCV(estimator = ElasticNet_pipe, \n",
    "                           search_spaces= {\n",
    "                                'model__alpha':Real(1e-6, 1, prior='log-uniform'),\n",
    "                                'model__l1_ratio':Real(1e-6, 1, prior='log-uniform')                          \n",
    "                           },\n",
    "                           scoring = scoring_func,\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1);\n",
    "bayes_search = bayes_search.fit(X_train, y_train);\n",
    "bayes_search.score(X_test,y_test), bayes_search.cv_results_['mean_test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = [ {'model__alpha': np.logspace(-1, 1,num=3),'model__l1_ratio':np.arange(0.4,0.8,0.1) } ]\n",
    "\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "scoring_func = make_scorer(mean_squared_error)\n",
    "# grid = dict()\n",
    "# grid['alpha'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.0, 1.0, 10.0, 100.0]\n",
    "# grid['l1_ratio'] = np.arange(0.3, 1, 0.01)\n",
    "grid_search = GridSearchCV(estimator = ElasticNet_pipe, \n",
    "                           param_grid = parameters,\n",
    "                           scoring = scoring_func,\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)  \n",
    "grid_search.score(X_test,y_test), grid_search.cv_results_['mean_test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2858.8668449384654, 2150.458635762094)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('scalar', StandardScaler()), ('feature_slection', SelectKBest(score_func=<function mutual_info_regression at 0x00000247574BCE00>)), ('poly', PolynomialFeatures(degree=3)), ('scalar2', StandardScaler()), ('model', Ridge(alpha=1.0028382472825777e-06))], 'verbose': False, 'scalar': StandardScaler(), 'feature_slection': SelectKBest(score_func=<function mutual_info_regression at 0x00000247574BCE00>), 'poly': PolynomialFeatures(degree=3), 'scalar2': StandardScaler(), 'model': Ridge(alpha=1.0028382472825777e-06), 'scalar__copy': True, 'scalar__with_mean': True, 'scalar__with_std': True, 'feature_slection__k': 10, 'feature_slection__score_func': <function mutual_info_regression at 0x00000247574BCE00>, 'poly__degree': 3, 'poly__include_bias': True, 'poly__interaction_only': False, 'poly__order': 'C', 'scalar2__copy': True, 'scalar2__with_mean': True, 'scalar2__with_std': True, 'model__alpha': 1.0028382472825777e-06, 'model__copy_X': True, 'model__fit_intercept': True, 'model__max_iter': None, 'model__normalize': 'deprecated', 'model__positive': False, 'model__random_state': None, 'model__solver': 'auto', 'model__tol': 0.001}\n",
      "Pipeline(steps=[('scalar', StandardScaler()),\n",
      "                ('feature_slection',\n",
      "                 SelectKBest(score_func=<function mutual_info_regression at 0x00000247574BCE00>)),\n",
      "                ('poly', PolynomialFeatures(degree=3)),\n",
      "                ('scalar2', StandardScaler()),\n",
      "                ('model', Ridge(alpha=1.0028382472825777e-06))])\n",
      "No es mejor:\n",
      "mse_new: 2272.4672457341258\n",
      "mse_best: 1816.4607473075173\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def saveIfGood(model,X_test,y_test):\n",
    "    # filenames = ['best_model_1.sav','best_model_2.sav','best_model.sav','best_model.sav','best_model.sav','best_model.sav','best_model.sav','best_model.sav']\n",
    "    filename = 'best_model.sav'\n",
    "    loaded_model = pickle.load(open(filename, 'rb'))\n",
    "    y_pred = loaded_model.predict(X_test)\n",
    "    y_pred_new = model.predict(X_test)\n",
    "    mse_new = mean_squared_error(y_test, y_pred_new)\n",
    "    mse_best = mean_squared_error(y_test, y_pred)\n",
    "    print(loaded_model.get_params())\n",
    "    print(loaded_model)\n",
    "\n",
    "    if mse_new < mse_best:\n",
    "        filename = 'best_model.sav'\n",
    "        saveModel(model,filename)\n",
    "        print(mse_new)\n",
    "        print(\"Se guardo mejor\")\n",
    "    else:\n",
    "        print(\"No es mejor:\")\n",
    "        print(\"mse_new:\",mse_new)\n",
    "        print(\"mse_best:\",mse_best)\n",
    "\n",
    "def saveModel(model,filename):\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "def ordenarModelos()\n",
    "\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    saveIfGood(filenames[i])\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "best_model = bayes_search.best_estimator_\n",
    "saveIfGood(best_model,X_test,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mod1769.sav'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'best_model.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "# y_pred_new = model.predict(X_test)\n",
    "# mse_new = mean_squared_error(y_test, y_pred_new)\n",
    "mse_best = mean_squared_error(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.set_params of Pipeline(steps=[('scalar', StandardScaler()),\n",
       "                ('feature_slection',\n",
       "                 SelectKBest(score_func=<function mutual_info_regression at 0x00000247574BCE00>)),\n",
       "                ('scalar2', StandardScaler()),\n",
       "                ('poly', PolynomialFeatures(degree=4)),\n",
       "                ('scalar3', StandardScaler()),\n",
       "                ('model', ElasticNet(alpha=0.5, l1_ratio=0.6))])>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ElasticNet_pipe.set_params('l1_ratio')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([132.01056822, 134.25371139, 123.7840261 , ...,  77.31698818,\n",
       "       149.75738482,   1.05178186])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2252.424293033005"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[y_pred<0] = 0\n",
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "df_y_pred = pd.DataFrame (y_pred)\n",
    "df_y_test = pd.DataFrame(y_test)\n",
    "y_comp  \n",
    "## save to xlsx file\n",
    "\n",
    "filepath_pred = 'my_excel_pred.xlsx'\n",
    "filepath = 'my_excel_file.xlsx'\n",
    "\n",
    "df_y_pred.to_excel(filepath_pred, index=False)\n",
    "df_y_test.to_excel(filepath, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scalar', StandardScaler()),\n",
       "  ('feature_slection',\n",
       "   SelectKBest(score_func=<function mutual_info_regression at 0x00000247574BCE00>)),\n",
       "  ('scalar2', StandardScaler()),\n",
       "  ('poly', PolynomialFeatures(degree=4)),\n",
       "  ('scalar3', StandardScaler()),\n",
       "  ('model', ElasticNet(l1_ratio=2.164263412821053e-05))],\n",
       " 'verbose': False,\n",
       " 'scalar': StandardScaler(),\n",
       " 'feature_slection': SelectKBest(score_func=<function mutual_info_regression at 0x00000247574BCE00>),\n",
       " 'scalar2': StandardScaler(),\n",
       " 'poly': PolynomialFeatures(degree=4),\n",
       " 'scalar3': StandardScaler(),\n",
       " 'model': ElasticNet(l1_ratio=2.164263412821053e-05),\n",
       " 'scalar__copy': True,\n",
       " 'scalar__with_mean': True,\n",
       " 'scalar__with_std': True,\n",
       " 'feature_slection__k': 10,\n",
       " 'feature_slection__score_func': <function sklearn.feature_selection._mutual_info.mutual_info_regression(X, y, *, discrete_features='auto', n_neighbors=3, copy=True, random_state=None)>,\n",
       " 'scalar2__copy': True,\n",
       " 'scalar2__with_mean': True,\n",
       " 'scalar2__with_std': True,\n",
       " 'poly__degree': 4,\n",
       " 'poly__include_bias': True,\n",
       " 'poly__interaction_only': False,\n",
       " 'poly__order': 'C',\n",
       " 'scalar3__copy': True,\n",
       " 'scalar3__with_mean': True,\n",
       " 'scalar3__with_std': True,\n",
       " 'model__alpha': 1.0,\n",
       " 'model__copy_X': True,\n",
       " 'model__fit_intercept': True,\n",
       " 'model__l1_ratio': 2.164263412821053e-05,\n",
       " 'model__max_iter': 1000,\n",
       " 'model__normalize': 'deprecated',\n",
       " 'model__positive': False,\n",
       " 'model__precompute': False,\n",
       " 'model__random_state': None,\n",
       " 'model__selection': 'cyclic',\n",
       " 'model__tol': 0.0001,\n",
       " 'model__warm_start': False}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.count_nonzero(y_pred>0)\n",
    "np.count_nonzero(y_test>=0)\n",
    "\n",
    "\n",
    "\n",
    "best_model.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
